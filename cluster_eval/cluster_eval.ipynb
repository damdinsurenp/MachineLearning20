{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the performance of clustering algorithms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/ageron/handson-ml2/blob/master/08_dimensionality_reduction.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead), as well as Scikit-Learn ≥0.20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"cluster_eval\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(input_file):\n",
    "    X = []\n",
    "    with open(input_file, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            data = [float(x) for x in line.split(',')]\n",
    "            X.append(data)\n",
    "\n",
    "    return np.array(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X = load_data('./data_perf.txt')\n",
    "\n",
    "# Plot data\n",
    "plt.plot(X[:, 0], X[:, 1], 'k.', markersize=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Silhouette coefficeint score\n",
    "\n",
    "A good way to measure a clustering algorithm is by seeing how well the clusters are separated. Silhouette Coefficient score is for each data point and the calculation is defined as follows:\n",
    "\n",
    "score = (a(i) - b(i)) / max(a(i), b(i)) for data point i. \n",
    "\n",
    "- a(i) is the average distance between the current data point i and all the other data points in the same cluster.\n",
    "\n",
    "- b(i) is the average distance between the current data point i and all the data points in the the nearest cluster. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. K-means clustering algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-means clustering evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# initialize scores and variables\n",
    "scores = []\n",
    "score_max = -1\n",
    "k_best = 0\n",
    "\n",
    "k_values = np.arange(2, 10)\n",
    "\n",
    "# k is the number of clusters\n",
    "# iterate through a range of k values and find the best\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "# Best params\n",
    "print('\\nBest k = {:} --> silhouette score: {:.4f}'.format(k_best, score_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Silhouette scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Silhouette scores\n",
    "plt.figure()\n",
    "plt.bar(k_values, scores, width=0.6, color='k', align='center')\n",
    "plt.title('Silhouette score vs number of clusters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Estimating the number of clusters using DBSCAN algorithm\n",
    "\n",
    "k-means algorithm requires the number of clusters as one of its parameters. In the real world, we wouldn't have this information available. We can definitely sweep the parameter space to find out the optimal number of clusters using the silhouette coefficient score (or the cost function), but thsi might be an expensive process. \n",
    "\n",
    "Another way we can find the number of clusters in the data is to apply the Density-Based Spatial Clustering of Applications with Noise (DBSCAN) algorithm. DBSCAN works by treating data points as groups of dense clusters. If a point belongs to a cluster, then there should be a lot of othe points that belong to the same cluster. One of the parameters that we can control is the maximum distance of this point from other points, which is called epsilon. No two points in a given cluster should be further away than epsilon. One of the main advantages of this algorithm is that it can deal with outliers. If there are some points located alone in a low-density area, DBSCAN will detect these points as outliers as opposed to forcing them into a cluster. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN clustering evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "\n",
    "# Find the best epsilon\n",
    "eps_grid = np.linspace(0.3, 1.2, num=10)\n",
    "\n",
    "silhouette_scores = []\n",
    "eps_best = eps_grid[0]\n",
    "\n",
    "silhouette_score_max = -1\n",
    "model_best = None\n",
    "labels_best = None\n",
    "\n",
    "# finding the best epsilon\n",
    "for eps in eps_grid:\n",
    "    # Train DBSCAN clustering model\n",
    "    model = DBSCAN(eps=eps, min_samples=5).fit(X)\n",
    "\n",
    "    # extract performance metric \n",
    "    silhouette_score = round(metrics.silhouette_score(X, model.labels_), 4)\n",
    "    silhouette_scores.append(silhouette_score)\n",
    "\n",
    "    print(\"Epsilon: {:.4f} --> silhouette score: {:.4f}\".format(eps, silhouette_score))\n",
    "\n",
    "    if silhouette_score > silhouette_score_max:\n",
    "        silhouette_score_max = silhouette_score\n",
    "        eps_best = eps\n",
    "        model_best = model\n",
    "        labels_best = model.labels_\n",
    "    \n",
    "# Best params\n",
    "print('\\nBest epsilon = {:.4f}'.format(eps_best))\n",
    "\n",
    "# Check for unassigned datapoints in the labels\n",
    "offset = 0\n",
    "if -1 in labels_best:\n",
    "    offset = 1\n",
    "\n",
    "# Number of clusters in the data \n",
    "num_clusters = len(set(labels_best)) - offset \n",
    "\n",
    "print(\"\\nEstimated number of clusters =\", num_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Silhouette scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot silhouette scores vs epsilon\n",
    "plt.figure()\n",
    "plt.bar(eps_grid, silhouette_scores, width=0.05, color='k', align='center')\n",
    "plt.title('Silhouette score vs epsilon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts the core samples from the trained model\n",
    "mask_core = np.zeros(labels_best.shape, dtype=np.bool)\n",
    "mask_core[model.core_sample_indices_] = True\n",
    "\n",
    "# Plot resultant clusters \n",
    "plt.figure()\n",
    "labels_uniq = set(labels_best)\n",
    "markers = cycle('vo^s<>')\n",
    "\n",
    "for cur_label, marker in zip(labels_uniq, markers):\n",
    "    # Use black dots for unassigned datapoints\n",
    "    if cur_label == -1:\n",
    "        marker = '.'\n",
    "\n",
    "    # Create mask for the current label\n",
    "    cur_mask = (labels_best == cur_label)\n",
    "\n",
    "    cur_data = X[cur_mask & mask_core]\n",
    "    plt.scatter(cur_data[:, 0], cur_data[:, 1], marker=marker,\n",
    "             edgecolors='black', s=96, facecolors='none')\n",
    "\n",
    "    cur_data = X[cur_mask & ~mask_core]\n",
    "    plt.scatter(cur_data[:, 0], cur_data[:, 1], marker=marker,\n",
    "             edgecolors='black', s=32)\n",
    "\n",
    "plt.title('Data separated into clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
